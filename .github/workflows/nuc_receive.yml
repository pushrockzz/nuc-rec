name: Receive and Process Nuclei Chunks

on:
  workflow_dispatch:
    inputs:
      # --- Inputs from the Primary Account's Trigger ---
      primary_github_server_url:
        description: 'The server URL of the primary GitHub instance (e.g., https://github.com)'
        required: true
      primary_repo_owner:
        description: 'The owner of the primary repository that triggered this workflow.'
        required: true
      primary_repo_name:
        description: 'The name of the primary repository.'
        required: true
      primary_run_id:
        description: 'The run_id of the primary workflow to download artifacts from.'
        required: true
      chunk_package_artifact_name:
        description: 'The name of the artifact containing all chunks and resolvers.'
        required: true
      secondary_matrix_json:
        description: 'The JSON string representing the matrix of chunks this account should process.'
        required: true

permissions:
  actions: read      # To download artifacts from the primary repository's workflow run
  contents: write    # To upload its own result artifacts

jobs:
  resolve_secondary_account_chunks:
    name: Resolve Secondary Account Chunks (nuclei
    runs-on: ubuntu-latest
    container:
      # Use the exact same container for consistency with the primary account
      image: ghcr.io/pcoder7/spider-puredns-actions:latest
      credentials:
        username: ${{ secrets.GHCR_USER }}
        password: ${{ secrets.GHCR_TOKEN }}
    strategy:
      fail-fast: false
      # The matrix is dynamically built from the input payload sent by Account 1
      matrix:
        pair: ${{ fromJson(github.event.inputs.secondary_matrix_json) }}
    steps:
      - name: Checkout repository (for results structure)
        uses: actions/checkout@v3

      - name: Download Full Chunks Package from Primary Account
        env:
          GH_TOKEN_PRIMARY_ACCOUNT_READ: ${{ secrets.PAT_FOR_PRIMARY_ACCOUNT_ARTIFACTS_READ }}
          PRIMARY_REPO_OWNER: ${{ github.event.inputs.primary_repo_owner }}
          PRIMARY_REPO_NAME: ${{ github.event.inputs.primary_repo_name }}
          PRIMARY_RUN_ID: ${{ github.event.inputs.primary_run_id }}
          ARTIFACT_NAME_FROM_PRIMARY: ${{ github.event.inputs.chunk_package_artifact_name }}
        shell: bash
        run: |
          echo "SECONDARY WORKER: Downloading artifact '$ARTIFACT_NAME_FROM_PRIMARY' from $PRIMARY_REPO_OWNER/$PRIMARY_REPO_NAME, run ID $PRIMARY_RUN_ID"
          if ! command -v gh &> /dev/null; then
            echo "INFO: gh CLI not found. Installing..."
            apt-get update -qy
            apt-get install -qy curl
            curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
            chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | tee /etc/apt/sources.list.d/github-cli.list > /dev/null
            apt-get update -qy
            apt-get install -qy gh
            if ! command -v gh &> /dev/null; then
              echo "ERROR: gh CLI installation failed."
              exit 1
            fi
          fi
          echo "$GH_TOKEN_PRIMARY_ACCOUNT_READ" | gh auth login --with-token
          FULL_PRIMARY_REPO="$PRIMARY_REPO_OWNER/$PRIMARY_REPO_NAME"
          gh run download "$PRIMARY_RUN_ID" -R "$FULL_PRIMARY_REPO" -n "$ARTIFACT_NAME_FROM_PRIMARY" --dir .
          PACKAGE_FILENAME="$ARTIFACT_NAME_FROM_PRIMARY.tar.gz"
          if [ ! -f "$PACKAGE_FILENAME" ]; then
            echo "ERROR: Failed to download '$PACKAGE_FILENAME'."
            exit 1
          fi
          echo "Downloaded '$PACKAGE_FILENAME'."
          
      - name: Extract Chunks for Secondary
        shell: bash
        run: |
          # The artifact is downloaded as a zip, we need to find and extract the tar.gz inside
          PACKAGE_FILENAME="${{ github.event.inputs.chunk_package_artifact_name }}.tar.gz"
          echo "Unzipping the downloaded artifact archive..."
          #unzip "${{ github.event.inputs.chunk_package_artifact_name }}.zip"
          echo "Extracting the main tarball: $PACKAGE_FILENAME..."
          tar -xzvf "$PACKAGE_FILENAME"
          if [ ! -d "chunks" ]; then
             echo "ERROR: 'chunks/' directory not found after extraction!"
             exit 1
          fi
          echo "Extraction complete. Listing contents of 'chunks/':"
          ls -R chunks/
          
      - name: Set up Go & install
        uses: actions/setup-go@v4
        with:
          go-version: '1.23'
          
      - name: Install dsieve
        run: |
          if command -v dsieve &> /dev/null; then
            echo "dsieve is already installed"
          else
            echo "Installing dsieve..."
            go install github.com/trickest/dsieve@latest
          fi
      - name: Run Nuc Scan
        # This step is an exact copy of the logic from the primary account's workflow
        # It uses the matrix context, which is now populated with the secondary chunks
        shell: bash
        run: |
          DOMAIN=${{ matrix.pair.domain }}
          CHUNK_FILE_PATH=${{ matrix.pair.chunk }}

          if [ ! -f "$CHUNK_FILE_PATH" ]; then
            echo "ERROR: Chunk file '$CHUNK_FILE_PATH' not found!"
            exit 1
          fi
          echo "-> Generating parent_domains.txt from raw subdomains..."
          #dsieve -if "$CHUNK_FILE_PATH" -f 2 | sort -u > parent_domains.txt
          
          OUTPUT_FILE="nuclei_output.txt"
          echo "-> Running nuc scan (100 rate-limit) against '$CHUNK_FILE_PATH'..."
          nuclei \
            -l "$CHUNK_FILE_PATH" \
            -t ~/nuclei-templates/http/exposed-panels \
            -ss template-spray \
            -c 10 \
            -bs 80 \
            -rl 100 \
            -prc 100 \
            -nc \
            -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36' \
            -silent \
            -o "$OUTPUT_FILE"
            
          if [ ! -s "$OUTPUT_FILE" ]; then
            echo "No live URLs found in this chunk. Exiting early."
            # Create empty results dir so artifact upload doesn't fail
            mkdir -p results
            exit 0
          fi
      
      - name: Install notify
        env: 
          DISCORD_WEBHOOK: ${{ secrets.DIS_WEBHOOK }}
        run: |
          go install -v github.com/projectdiscovery/notify/cmd/notify@latest
          mkdir -p ~/.config/notify/
          cat <<EOF > ~/.config/notify/provider-config.yaml
              # Write provider config with our Discord webhook
          discord:
            - id: "subscan"
              discord_channel: "subdomain-scan"
              discord_format: "{{data}}"
              discord_webhook_url: "${{ secrets.DIS_WEBHOOK }}"
          EOF
          echo "$HOME/go/bin" >> $GITHUB_PATH
          # display and show provider-config.yaml file
          cat ~/.config/notify/provider-config.yaml  
     
      - name: Show notify config
        run: | 
          echo "$DIS_WEBHOOK"
          sed -e 's/.*/&/' ~/.config/notify/provider-config.yaml
        env:
          DISCORD_WEBHOOK: ${{ secrets.DIS_WEBHOOK }}         

      - name: Notify Discord for Nuc scab
        run: |
          # 1. Capture todayâ€™s date and the current domain
          DATE=$(date +"%d-%m-%Y")
          DOMAIN="${{ matrix.pair.domain }}"
      
          # 2. Path to the file with only the new subdomains
          FILE="nuclei_output.txt"
      
          # 3. Count how many new subdomains we have
          COUNT=$(wc -l < "$FILE")
      
          # 4. If more than 50, send a header message, then the file
          if [ "$COUNT" -gt 3 ]; then
            # 4a. Send a text header with domain and date
            echo -e "ðŸ”” $COUNT New Entry for ${DOMAIN}\nðŸ“… Date: ${DATE}" \
              | notify -id subscan
            # 4b. Send the full list as a file
            notify -bulk -id subscan -data "$FILE"
          else
            # 5. If 1â€“50 new entries, send one bulk message including header and list
            {
              echo "ðŸ”” $COUNT New Entry"
              echo "ðŸ“… Date: ${DATE}"
              echo
              cat "$FILE"
            } | notify -bulk -id subscan
          fi      
          
